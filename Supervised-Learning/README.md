
## **History - A Statistician's Perspective**

### **Statistics**

The statistician's perspective has evolved from understanding data. The field of data analysis was originally a field of *mathematics* based on questions like, how do we better understand the mechanisms that create data? From these questions, probability-based models were used to model the world around us.

> For example, there's a distribution to model expected scores on a test, number of daily incidence on a stretch of road, or how frequently words show up in a body of text.
> 

The derivation of distributions like these were breakthroughs for mechanisms that could create data in the real world. These mathematical functions were used to describe essentially all aspects of our daily lives.

However, these models are an oversimplification of the complexities that exist in the real world. Often, the probability-based models that were created for a situation did not do a very good job of simulating the actual data observed in the world.

## **History - A Computer Scientist's Perspective**

### **Computer Science**

In the 1950s, computer scientists were coming to the realization that it might be best if they didn't hard-code every decision a computer would make as essentially never-ending if-else statements, rather the computer should determine what was best by looking at data and recognizing patterns.

> This idea of recognizing patterns and data is what is commonly recognized as machine learning.
> 

Drawing from the world of statistics, in order to avoid hard-coding rules, these new techniques involved rules that were based on distributions. But using statistical distributions as generators of data, exposed pretty large discrepancies between the data generated by our models and the data you actually obtained in the real life.

Machine learning has continued to evolve into extremely flexible models based more and more on data and less and less on human-enforced if-else statements. These flexible models have been shown to predict better than previous well-defined modeling techniques. This leads to the current state of machine learning where prediction has become key often creating extremely flexible and complex models.

These complex models outperform models

- Hard-coded if-else statements set up by humans
- Distributions known as well-known probability distributions.

Unfortunately, these complex models often leave the **why** of a prediction unknown. Though these techniques might be able to identify tumors better than doctors or play at a world-class level in the game of Go, the individuals creating these models can't always explain *why they're making these decisions.*

## Ethics in Machine learning:

Since the data in our world often holds errors and biases, the models we build will hold the same errors and biases.

As an example, imagine you want to build a model to predict who the best candidate is for a job based on existing data.

If there were biases and historical hiring patterns based on gender, race, age, economic status et cetera, these biases are going to be held by any predictive model you build based on these data.

Unfortunately, the bias held by humans will transfer to computers so long as humans are the creators of the data. Images, text, speech, and video are all human-generated data being ingested by computers in today's world to make data-based decisions.

The potential biases in the data created as a result of our human biases should always be on your mind when building your models.

> Real-world validation of your models is even more important than statistical validation.
> 

## **Supervised Learning**

In supervised machine learning, our algorithms learn from labeled data. After studying the labeled data, these techniques are able to determine which label should be given to new data based on observing patterns and associating those patterns to new unlabeled data. Supervised learning can be divided into two categories:

- **Classification**
    - Models that predict a category that an item belongs to. In some cases used for events with only two possible outcomes, like whether an email is spam or not, but also can be extended to predict any number of categories such as predicting which of many breeds a dog belongs to.
- **Regression**
    - Models that predict a numeric value like home price or an individual's height.
